{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "HR5U_6oajPuB"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "tv5DNHcdm8oc"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_breast_cancer()"
      ],
      "metadata": {
        "id": "YIuqpkeGjoPH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data['data']"
      ],
      "metadata": {
        "id": "YjdM97RWj1p2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = data['target']"
      ],
      "metadata": {
        "id": "8agaCJ36j-pG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0CKyr3wkCZ4",
        "outputId": "154f494f-fb40-45fc-f152-eb4f9202250c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
              "        1.189e-01],\n",
              "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
              "        8.902e-02],\n",
              "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
              "        8.758e-02],\n",
              "       ...,\n",
              "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
              "        7.820e-02],\n",
              "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
              "        1.240e-01],\n",
              "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
              "        7.039e-02]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIKuISVikMvB",
        "outputId": "3f7b190f-f68c-4320-840c-59d983c29218"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
              "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_X, test_X, train_y, test_y = train_test_split(X,y, test_size = 0.3, random_state=6)"
      ],
      "metadata": {
        "id": "n2PYnIYSkNzo"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(y).value_counts(normalize = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oijzflDVlUgU",
        "outputId": "d5b5d7de-2b9d-49d2-ecb1-0701e9bc4907"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    0.627417\n",
              "0    0.372583\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(train_y).value_counts(normalize = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KagA-1C2lfJG",
        "outputId": "2380c6e4-ac28-46df-f113-20a490c07dd1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    0.653266\n",
              "0    0.346734\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(test_y).value_counts(normalize = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mphAgmdlmfHI",
        "outputId": "6f607e83-b157-436b-8331-0fc6535a458f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    0.567251\n",
              "0    0.432749\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_X, test_X, train_y, test_y = train_test_split(X,y, test_size = 0.3, random_state=234, stratify = y)"
      ],
      "metadata": {
        "id": "kv73Xx6zmjHu"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(train_y).value_counts(normalize = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3RWM4oRmqLg",
        "outputId": "53214dc7-c4a4-4dcf-fc85-094cad0fd57d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    0.628141\n",
              "0    0.371859\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(test_y).value_counts(normalize = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUj5HKSAmrRs",
        "outputId": "5f9bcc45-647d-42f0-e9ec-7dce742dd5e1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    0.625731\n",
              "0    0.374269\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAn3JZiUn55A",
        "outputId": "0ff67331-36a4-4dbc-cd1c-3e6ad6b26eba"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(398, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_X.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1Ws4rN0n_UH",
        "outputId": "d7571248-5c8f-4215-c7f2-41d768bc57ee"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "metadata": {
        "id": "vdRpmcYomsUd"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dense(32, input_shape = (train_X.shape[1],), activation = 'sigmoid'))\n",
        "model.add(Dense(16, activation = 'sigmoid'))\n",
        "model.add(Dense(8, activation = 'sigmoid'))\n",
        "model.add(Dense(4, activation = 'sigmoid'))\n",
        "model.add(Dense(2, activation = 'sigmoid'))\n",
        "model.add(Dense(1, activation = 'sigmoid'))"
      ],
      "metadata": {
        "id": "AculBFNQnuTR"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optim = SGD()\n",
        "model.compile(optimizer = optim, loss = 'binary_crossentropy', metrics = ['accuracy'] )"
      ],
      "metadata": {
        "id": "hdl8iTEgoRW2"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t75QpqNuo20w",
        "outputId": "ce108a5d-21ce-48b2-9628-2862b9d2278c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 32)                992       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4)                 36        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 2)                 10        \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1705 (6.66 KB)\n",
            "Trainable params: 1705 (6.66 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_X, train_y, epochs = 100, batch_size = 100, verbose = 2, validation_data= (test_X,test_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyJ90vSPo6DI",
        "outputId": "6f480457-400a-482c-eeee-85bc82707f89"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "4/4 - 6s - loss: 0.7704 - accuracy: 0.3719 - val_loss: 0.7672 - val_accuracy: 0.3743 - 6s/epoch - 2s/step\n",
            "Epoch 2/100\n",
            "4/4 - 0s - loss: 0.7669 - accuracy: 0.3719 - val_loss: 0.7638 - val_accuracy: 0.3743 - 79ms/epoch - 20ms/step\n",
            "Epoch 3/100\n",
            "4/4 - 0s - loss: 0.7636 - accuracy: 0.3719 - val_loss: 0.7606 - val_accuracy: 0.3743 - 64ms/epoch - 16ms/step\n",
            "Epoch 4/100\n",
            "4/4 - 0s - loss: 0.7603 - accuracy: 0.3719 - val_loss: 0.7575 - val_accuracy: 0.3743 - 80ms/epoch - 20ms/step\n",
            "Epoch 5/100\n",
            "4/4 - 0s - loss: 0.7572 - accuracy: 0.3719 - val_loss: 0.7544 - val_accuracy: 0.3743 - 77ms/epoch - 19ms/step\n",
            "Epoch 6/100\n",
            "4/4 - 0s - loss: 0.7542 - accuracy: 0.3719 - val_loss: 0.7515 - val_accuracy: 0.3743 - 65ms/epoch - 16ms/step\n",
            "Epoch 7/100\n",
            "4/4 - 0s - loss: 0.7513 - accuracy: 0.3719 - val_loss: 0.7487 - val_accuracy: 0.3743 - 75ms/epoch - 19ms/step\n",
            "Epoch 8/100\n",
            "4/4 - 0s - loss: 0.7484 - accuracy: 0.3719 - val_loss: 0.7459 - val_accuracy: 0.3743 - 83ms/epoch - 21ms/step\n",
            "Epoch 9/100\n",
            "4/4 - 0s - loss: 0.7457 - accuracy: 0.3719 - val_loss: 0.7433 - val_accuracy: 0.3743 - 74ms/epoch - 19ms/step\n",
            "Epoch 10/100\n",
            "4/4 - 0s - loss: 0.7430 - accuracy: 0.3719 - val_loss: 0.7407 - val_accuracy: 0.3743 - 75ms/epoch - 19ms/step\n",
            "Epoch 11/100\n",
            "4/4 - 0s - loss: 0.7405 - accuracy: 0.3719 - val_loss: 0.7382 - val_accuracy: 0.3743 - 78ms/epoch - 19ms/step\n",
            "Epoch 12/100\n",
            "4/4 - 0s - loss: 0.7380 - accuracy: 0.3719 - val_loss: 0.7358 - val_accuracy: 0.3743 - 74ms/epoch - 19ms/step\n",
            "Epoch 13/100\n",
            "4/4 - 0s - loss: 0.7356 - accuracy: 0.3719 - val_loss: 0.7335 - val_accuracy: 0.3743 - 75ms/epoch - 19ms/step\n",
            "Epoch 14/100\n",
            "4/4 - 0s - loss: 0.7333 - accuracy: 0.3719 - val_loss: 0.7312 - val_accuracy: 0.3743 - 70ms/epoch - 18ms/step\n",
            "Epoch 15/100\n",
            "4/4 - 0s - loss: 0.7310 - accuracy: 0.3719 - val_loss: 0.7290 - val_accuracy: 0.3743 - 63ms/epoch - 16ms/step\n",
            "Epoch 16/100\n",
            "4/4 - 0s - loss: 0.7288 - accuracy: 0.3719 - val_loss: 0.7269 - val_accuracy: 0.3743 - 80ms/epoch - 20ms/step\n",
            "Epoch 17/100\n",
            "4/4 - 0s - loss: 0.7267 - accuracy: 0.3719 - val_loss: 0.7249 - val_accuracy: 0.3743 - 70ms/epoch - 17ms/step\n",
            "Epoch 18/100\n",
            "4/4 - 0s - loss: 0.7247 - accuracy: 0.3719 - val_loss: 0.7229 - val_accuracy: 0.3743 - 60ms/epoch - 15ms/step\n",
            "Epoch 19/100\n",
            "4/4 - 0s - loss: 0.7227 - accuracy: 0.3719 - val_loss: 0.7210 - val_accuracy: 0.3743 - 71ms/epoch - 18ms/step\n",
            "Epoch 20/100\n",
            "4/4 - 0s - loss: 0.7208 - accuracy: 0.3719 - val_loss: 0.7191 - val_accuracy: 0.3743 - 72ms/epoch - 18ms/step\n",
            "Epoch 21/100\n",
            "4/4 - 0s - loss: 0.7189 - accuracy: 0.3719 - val_loss: 0.7173 - val_accuracy: 0.3743 - 78ms/epoch - 19ms/step\n",
            "Epoch 22/100\n",
            "4/4 - 0s - loss: 0.7171 - accuracy: 0.3719 - val_loss: 0.7156 - val_accuracy: 0.3743 - 77ms/epoch - 19ms/step\n",
            "Epoch 23/100\n",
            "4/4 - 0s - loss: 0.7153 - accuracy: 0.3719 - val_loss: 0.7139 - val_accuracy: 0.3743 - 74ms/epoch - 18ms/step\n",
            "Epoch 24/100\n",
            "4/4 - 0s - loss: 0.7136 - accuracy: 0.3719 - val_loss: 0.7123 - val_accuracy: 0.3743 - 45ms/epoch - 11ms/step\n",
            "Epoch 25/100\n",
            "4/4 - 0s - loss: 0.7120 - accuracy: 0.3719 - val_loss: 0.7107 - val_accuracy: 0.3743 - 58ms/epoch - 15ms/step\n",
            "Epoch 26/100\n",
            "4/4 - 0s - loss: 0.7104 - accuracy: 0.3719 - val_loss: 0.7092 - val_accuracy: 0.3743 - 43ms/epoch - 11ms/step\n",
            "Epoch 27/100\n",
            "4/4 - 0s - loss: 0.7089 - accuracy: 0.3719 - val_loss: 0.7077 - val_accuracy: 0.3743 - 59ms/epoch - 15ms/step\n",
            "Epoch 28/100\n",
            "4/4 - 0s - loss: 0.7074 - accuracy: 0.3719 - val_loss: 0.7063 - val_accuracy: 0.3743 - 62ms/epoch - 15ms/step\n",
            "Epoch 29/100\n",
            "4/4 - 0s - loss: 0.7060 - accuracy: 0.3719 - val_loss: 0.7049 - val_accuracy: 0.3743 - 47ms/epoch - 12ms/step\n",
            "Epoch 30/100\n",
            "4/4 - 0s - loss: 0.7046 - accuracy: 0.3719 - val_loss: 0.7035 - val_accuracy: 0.3743 - 43ms/epoch - 11ms/step\n",
            "Epoch 31/100\n",
            "4/4 - 0s - loss: 0.7032 - accuracy: 0.3719 - val_loss: 0.7022 - val_accuracy: 0.3743 - 59ms/epoch - 15ms/step\n",
            "Epoch 32/100\n",
            "4/4 - 0s - loss: 0.7019 - accuracy: 0.3719 - val_loss: 0.7010 - val_accuracy: 0.3743 - 64ms/epoch - 16ms/step\n",
            "Epoch 33/100\n",
            "4/4 - 0s - loss: 0.7007 - accuracy: 0.3719 - val_loss: 0.6998 - val_accuracy: 0.3743 - 61ms/epoch - 15ms/step\n",
            "Epoch 34/100\n",
            "4/4 - 0s - loss: 0.6994 - accuracy: 0.3719 - val_loss: 0.6986 - val_accuracy: 0.3743 - 58ms/epoch - 15ms/step\n",
            "Epoch 35/100\n",
            "4/4 - 0s - loss: 0.6983 - accuracy: 0.3719 - val_loss: 0.6974 - val_accuracy: 0.3743 - 45ms/epoch - 11ms/step\n",
            "Epoch 36/100\n",
            "4/4 - 0s - loss: 0.6971 - accuracy: 0.3719 - val_loss: 0.6963 - val_accuracy: 0.3743 - 60ms/epoch - 15ms/step\n",
            "Epoch 37/100\n",
            "4/4 - 0s - loss: 0.6960 - accuracy: 0.3719 - val_loss: 0.6952 - val_accuracy: 0.3743 - 62ms/epoch - 16ms/step\n",
            "Epoch 38/100\n",
            "4/4 - 0s - loss: 0.6949 - accuracy: 0.3719 - val_loss: 0.6942 - val_accuracy: 0.3743 - 46ms/epoch - 11ms/step\n",
            "Epoch 39/100\n",
            "4/4 - 0s - loss: 0.6939 - accuracy: 0.3719 - val_loss: 0.6932 - val_accuracy: 0.3684 - 58ms/epoch - 14ms/step\n",
            "Epoch 40/100\n",
            "4/4 - 0s - loss: 0.6928 - accuracy: 0.5704 - val_loss: 0.6922 - val_accuracy: 0.6257 - 39ms/epoch - 10ms/step\n",
            "Epoch 41/100\n",
            "4/4 - 0s - loss: 0.6918 - accuracy: 0.6281 - val_loss: 0.6913 - val_accuracy: 0.6257 - 41ms/epoch - 10ms/step\n",
            "Epoch 42/100\n",
            "4/4 - 0s - loss: 0.6909 - accuracy: 0.6281 - val_loss: 0.6903 - val_accuracy: 0.6257 - 42ms/epoch - 10ms/step\n",
            "Epoch 43/100\n",
            "4/4 - 0s - loss: 0.6899 - accuracy: 0.6281 - val_loss: 0.6895 - val_accuracy: 0.6257 - 57ms/epoch - 14ms/step\n",
            "Epoch 44/100\n",
            "4/4 - 0s - loss: 0.6891 - accuracy: 0.6281 - val_loss: 0.6886 - val_accuracy: 0.6257 - 44ms/epoch - 11ms/step\n",
            "Epoch 45/100\n",
            "4/4 - 0s - loss: 0.6882 - accuracy: 0.6281 - val_loss: 0.6878 - val_accuracy: 0.6257 - 57ms/epoch - 14ms/step\n",
            "Epoch 46/100\n",
            "4/4 - 0s - loss: 0.6874 - accuracy: 0.6281 - val_loss: 0.6870 - val_accuracy: 0.6257 - 60ms/epoch - 15ms/step\n",
            "Epoch 47/100\n",
            "4/4 - 0s - loss: 0.6865 - accuracy: 0.6281 - val_loss: 0.6862 - val_accuracy: 0.6257 - 65ms/epoch - 16ms/step\n",
            "Epoch 48/100\n",
            "4/4 - 0s - loss: 0.6857 - accuracy: 0.6281 - val_loss: 0.6854 - val_accuracy: 0.6257 - 58ms/epoch - 15ms/step\n",
            "Epoch 49/100\n",
            "4/4 - 0s - loss: 0.6850 - accuracy: 0.6281 - val_loss: 0.6847 - val_accuracy: 0.6257 - 42ms/epoch - 10ms/step\n",
            "Epoch 50/100\n",
            "4/4 - 0s - loss: 0.6842 - accuracy: 0.6281 - val_loss: 0.6840 - val_accuracy: 0.6257 - 59ms/epoch - 15ms/step\n",
            "Epoch 51/100\n",
            "4/4 - 0s - loss: 0.6835 - accuracy: 0.6281 - val_loss: 0.6833 - val_accuracy: 0.6257 - 59ms/epoch - 15ms/step\n",
            "Epoch 52/100\n",
            "4/4 - 0s - loss: 0.6828 - accuracy: 0.6281 - val_loss: 0.6826 - val_accuracy: 0.6257 - 48ms/epoch - 12ms/step\n",
            "Epoch 53/100\n",
            "4/4 - 0s - loss: 0.6821 - accuracy: 0.6281 - val_loss: 0.6820 - val_accuracy: 0.6257 - 48ms/epoch - 12ms/step\n",
            "Epoch 54/100\n",
            "4/4 - 0s - loss: 0.6815 - accuracy: 0.6281 - val_loss: 0.6813 - val_accuracy: 0.6257 - 51ms/epoch - 13ms/step\n",
            "Epoch 55/100\n",
            "4/4 - 0s - loss: 0.6809 - accuracy: 0.6281 - val_loss: 0.6807 - val_accuracy: 0.6257 - 46ms/epoch - 12ms/step\n",
            "Epoch 56/100\n",
            "4/4 - 0s - loss: 0.6802 - accuracy: 0.6281 - val_loss: 0.6801 - val_accuracy: 0.6257 - 53ms/epoch - 13ms/step\n",
            "Epoch 57/100\n",
            "4/4 - 0s - loss: 0.6796 - accuracy: 0.6281 - val_loss: 0.6796 - val_accuracy: 0.6257 - 50ms/epoch - 13ms/step\n",
            "Epoch 58/100\n",
            "4/4 - 0s - loss: 0.6791 - accuracy: 0.6281 - val_loss: 0.6790 - val_accuracy: 0.6257 - 52ms/epoch - 13ms/step\n",
            "Epoch 59/100\n",
            "4/4 - 0s - loss: 0.6785 - accuracy: 0.6281 - val_loss: 0.6785 - val_accuracy: 0.6257 - 45ms/epoch - 11ms/step\n",
            "Epoch 60/100\n",
            "4/4 - 0s - loss: 0.6779 - accuracy: 0.6281 - val_loss: 0.6779 - val_accuracy: 0.6257 - 43ms/epoch - 11ms/step\n",
            "Epoch 61/100\n",
            "4/4 - 0s - loss: 0.6774 - accuracy: 0.6281 - val_loss: 0.6774 - val_accuracy: 0.6257 - 60ms/epoch - 15ms/step\n",
            "Epoch 62/100\n",
            "4/4 - 0s - loss: 0.6769 - accuracy: 0.6281 - val_loss: 0.6770 - val_accuracy: 0.6257 - 62ms/epoch - 15ms/step\n",
            "Epoch 63/100\n",
            "4/4 - 0s - loss: 0.6764 - accuracy: 0.6281 - val_loss: 0.6765 - val_accuracy: 0.6257 - 44ms/epoch - 11ms/step\n",
            "Epoch 64/100\n",
            "4/4 - 0s - loss: 0.6759 - accuracy: 0.6281 - val_loss: 0.6760 - val_accuracy: 0.6257 - 41ms/epoch - 10ms/step\n",
            "Epoch 65/100\n",
            "4/4 - 0s - loss: 0.6754 - accuracy: 0.6281 - val_loss: 0.6756 - val_accuracy: 0.6257 - 59ms/epoch - 15ms/step\n",
            "Epoch 66/100\n",
            "4/4 - 0s - loss: 0.6750 - accuracy: 0.6281 - val_loss: 0.6751 - val_accuracy: 0.6257 - 62ms/epoch - 16ms/step\n",
            "Epoch 67/100\n",
            "4/4 - 0s - loss: 0.6746 - accuracy: 0.6281 - val_loss: 0.6747 - val_accuracy: 0.6257 - 61ms/epoch - 15ms/step\n",
            "Epoch 68/100\n",
            "4/4 - 0s - loss: 0.6741 - accuracy: 0.6281 - val_loss: 0.6743 - val_accuracy: 0.6257 - 61ms/epoch - 15ms/step\n",
            "Epoch 69/100\n",
            "4/4 - 0s - loss: 0.6737 - accuracy: 0.6281 - val_loss: 0.6739 - val_accuracy: 0.6257 - 45ms/epoch - 11ms/step\n",
            "Epoch 70/100\n",
            "4/4 - 0s - loss: 0.6733 - accuracy: 0.6281 - val_loss: 0.6735 - val_accuracy: 0.6257 - 44ms/epoch - 11ms/step\n",
            "Epoch 71/100\n",
            "4/4 - 0s - loss: 0.6729 - accuracy: 0.6281 - val_loss: 0.6732 - val_accuracy: 0.6257 - 46ms/epoch - 11ms/step\n",
            "Epoch 72/100\n",
            "4/4 - 0s - loss: 0.6726 - accuracy: 0.6281 - val_loss: 0.6728 - val_accuracy: 0.6257 - 50ms/epoch - 12ms/step\n",
            "Epoch 73/100\n",
            "4/4 - 0s - loss: 0.6722 - accuracy: 0.6281 - val_loss: 0.6725 - val_accuracy: 0.6257 - 43ms/epoch - 11ms/step\n",
            "Epoch 74/100\n",
            "4/4 - 0s - loss: 0.6718 - accuracy: 0.6281 - val_loss: 0.6721 - val_accuracy: 0.6257 - 43ms/epoch - 11ms/step\n",
            "Epoch 75/100\n",
            "4/4 - 0s - loss: 0.6715 - accuracy: 0.6281 - val_loss: 0.6718 - val_accuracy: 0.6257 - 45ms/epoch - 11ms/step\n",
            "Epoch 76/100\n",
            "4/4 - 0s - loss: 0.6711 - accuracy: 0.6281 - val_loss: 0.6715 - val_accuracy: 0.6257 - 60ms/epoch - 15ms/step\n",
            "Epoch 77/100\n",
            "4/4 - 0s - loss: 0.6708 - accuracy: 0.6281 - val_loss: 0.6712 - val_accuracy: 0.6257 - 44ms/epoch - 11ms/step\n",
            "Epoch 78/100\n",
            "4/4 - 0s - loss: 0.6705 - accuracy: 0.6281 - val_loss: 0.6709 - val_accuracy: 0.6257 - 46ms/epoch - 11ms/step\n",
            "Epoch 79/100\n",
            "4/4 - 0s - loss: 0.6702 - accuracy: 0.6281 - val_loss: 0.6706 - val_accuracy: 0.6257 - 60ms/epoch - 15ms/step\n",
            "Epoch 80/100\n",
            "4/4 - 0s - loss: 0.6699 - accuracy: 0.6281 - val_loss: 0.6703 - val_accuracy: 0.6257 - 61ms/epoch - 15ms/step\n",
            "Epoch 81/100\n",
            "4/4 - 0s - loss: 0.6696 - accuracy: 0.6281 - val_loss: 0.6700 - val_accuracy: 0.6257 - 44ms/epoch - 11ms/step\n",
            "Epoch 82/100\n",
            "4/4 - 0s - loss: 0.6693 - accuracy: 0.6281 - val_loss: 0.6697 - val_accuracy: 0.6257 - 44ms/epoch - 11ms/step\n",
            "Epoch 83/100\n",
            "4/4 - 0s - loss: 0.6690 - accuracy: 0.6281 - val_loss: 0.6695 - val_accuracy: 0.6257 - 45ms/epoch - 11ms/step\n",
            "Epoch 84/100\n",
            "4/4 - 0s - loss: 0.6688 - accuracy: 0.6281 - val_loss: 0.6692 - val_accuracy: 0.6257 - 62ms/epoch - 15ms/step\n",
            "Epoch 85/100\n",
            "4/4 - 0s - loss: 0.6685 - accuracy: 0.6281 - val_loss: 0.6690 - val_accuracy: 0.6257 - 44ms/epoch - 11ms/step\n",
            "Epoch 86/100\n",
            "4/4 - 0s - loss: 0.6683 - accuracy: 0.6281 - val_loss: 0.6688 - val_accuracy: 0.6257 - 58ms/epoch - 15ms/step\n",
            "Epoch 87/100\n",
            "4/4 - 0s - loss: 0.6681 - accuracy: 0.6281 - val_loss: 0.6685 - val_accuracy: 0.6257 - 45ms/epoch - 11ms/step\n",
            "Epoch 88/100\n",
            "4/4 - 0s - loss: 0.6678 - accuracy: 0.6281 - val_loss: 0.6683 - val_accuracy: 0.6257 - 59ms/epoch - 15ms/step\n",
            "Epoch 89/100\n",
            "4/4 - 0s - loss: 0.6676 - accuracy: 0.6281 - val_loss: 0.6681 - val_accuracy: 0.6257 - 61ms/epoch - 15ms/step\n",
            "Epoch 90/100\n",
            "4/4 - 0s - loss: 0.6674 - accuracy: 0.6281 - val_loss: 0.6679 - val_accuracy: 0.6257 - 50ms/epoch - 13ms/step\n",
            "Epoch 91/100\n",
            "4/4 - 0s - loss: 0.6671 - accuracy: 0.6281 - val_loss: 0.6677 - val_accuracy: 0.6257 - 61ms/epoch - 15ms/step\n",
            "Epoch 92/100\n",
            "4/4 - 0s - loss: 0.6669 - accuracy: 0.6281 - val_loss: 0.6675 - val_accuracy: 0.6257 - 46ms/epoch - 11ms/step\n",
            "Epoch 93/100\n",
            "4/4 - 0s - loss: 0.6667 - accuracy: 0.6281 - val_loss: 0.6673 - val_accuracy: 0.6257 - 57ms/epoch - 14ms/step\n",
            "Epoch 94/100\n",
            "4/4 - 0s - loss: 0.6665 - accuracy: 0.6281 - val_loss: 0.6671 - val_accuracy: 0.6257 - 42ms/epoch - 11ms/step\n",
            "Epoch 95/100\n",
            "4/4 - 0s - loss: 0.6664 - accuracy: 0.6281 - val_loss: 0.6669 - val_accuracy: 0.6257 - 43ms/epoch - 11ms/step\n",
            "Epoch 96/100\n",
            "4/4 - 0s - loss: 0.6662 - accuracy: 0.6281 - val_loss: 0.6668 - val_accuracy: 0.6257 - 56ms/epoch - 14ms/step\n",
            "Epoch 97/100\n",
            "4/4 - 0s - loss: 0.6660 - accuracy: 0.6281 - val_loss: 0.6666 - val_accuracy: 0.6257 - 45ms/epoch - 11ms/step\n",
            "Epoch 98/100\n",
            "4/4 - 0s - loss: 0.6658 - accuracy: 0.6281 - val_loss: 0.6664 - val_accuracy: 0.6257 - 48ms/epoch - 12ms/step\n",
            "Epoch 99/100\n",
            "4/4 - 0s - loss: 0.6656 - accuracy: 0.6281 - val_loss: 0.6663 - val_accuracy: 0.6257 - 48ms/epoch - 12ms/step\n",
            "Epoch 100/100\n",
            "4/4 - 0s - loss: 0.6655 - accuracy: 0.6281 - val_loss: 0.6661 - val_accuracy: 0.6257 - 48ms/epoch - 12ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78674c3717e0>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(train_X,train_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaO1au2_ptdO",
        "outputId": "04732a73-79ba-4d4d-8061-1f2689d8f857"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6654 - accuracy: 0.6281\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6653720140457153, 0.6281406879425049]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_X,test_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SL9sE0rLp9a1",
        "outputId": "49221fb3-849c-4f9b-db4f-480c4005260a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6661 - accuracy: 0.6257\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6661239862442017, 0.6257309913635254]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(test_X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQofATh7qFAs",
        "outputId": "2123140b-cf31-4873-ba3b-6216f4b2b61d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.57676893],\n",
              "       [0.5766836 ],\n",
              "       [0.57676244],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.5766837 ],\n",
              "       [0.5766836 ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.5767366 ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.5766836 ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.5766084 ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.57676893],\n",
              "       [0.576769  ],\n",
              "       [0.5765993 ],\n",
              "       [0.576769  ],\n",
              "       [0.5766836 ],\n",
              "       [0.5766836 ],\n",
              "       [0.576769  ],\n",
              "       [0.57686985],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.5767684 ],\n",
              "       [0.576769  ],\n",
              "       [0.57668287],\n",
              "       [0.576769  ],\n",
              "       [0.5767685 ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.5766836 ],\n",
              "       [0.5766836 ],\n",
              "       [0.5766836 ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.5766196 ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.57666963],\n",
              "       [0.576769  ],\n",
              "       [0.5766885 ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.57668567],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.57674086],\n",
              "       [0.57667637],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.5766836 ],\n",
              "       [0.57676876],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.5767688 ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.5767684 ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.5766073 ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.5766836 ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.5766069 ],\n",
              "       [0.5766836 ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.5766836 ],\n",
              "       [0.5767692 ],\n",
              "       [0.5767691 ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.5767692 ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.57676846],\n",
              "       [0.5767635 ],\n",
              "       [0.5767687 ],\n",
              "       [0.57676893],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.5766836 ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.57677144],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.5767685 ],\n",
              "       [0.576769  ],\n",
              "       [0.57676893],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.57675797],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.5766836 ],\n",
              "       [0.576769  ],\n",
              "       [0.5767693 ],\n",
              "       [0.576769  ],\n",
              "       [0.5766907 ],\n",
              "       [0.5766836 ],\n",
              "       [0.5773185 ],\n",
              "       [0.5766836 ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.5767692 ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.5766836 ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.5766836 ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.576769  ],\n",
              "       [0.5766836 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K34ahg1iqNj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DRnBZyExq-KC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z_rG-i8Pq-Mp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Softmax in output layer"
      ],
      "metadata": {
        "id": "7AuCZ62-rDYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_cat = to_categorical(y)"
      ],
      "metadata": {
        "id": "M685CAe7q-PB"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X, test_X, train_y, test_y = train_test_split(X,y_cat, test_size = 0.3, random_state=6)"
      ],
      "metadata": {
        "id": "l_wcfUqerIjI"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bz2oYpp4rMr6"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "metadata": {
        "id": "ZP4yzvQOrhdd"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dense(32, input_shape = (train_X.shape[1],), activation = 'sigmoid'))\n",
        "model.add(Dense(16, activation = 'sigmoid'))\n",
        "model.add(Dense(8, activation = 'sigmoid'))\n",
        "model.add(Dense(4, activation = 'sigmoid'))\n",
        "model.add(Dense(2, activation = 'sigmoid'))\n",
        "model.add(Dense(2, activation = 'softmax'))"
      ],
      "metadata": {
        "id": "q3hmwiHdrhdm"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optim = SGD()\n",
        "model.compile(optimizer = optim, loss = 'binary_crossentropy', metrics = ['accuracy'] )"
      ],
      "metadata": {
        "id": "3eijuIW3rhdm"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "076f67a4-2b35-428b-c641-b27ab3dfb321",
        "id": "HL4mSW0Urhdm"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_24 (Dense)            (None, 32)                992       \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 4)                 36        \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 2)                 10        \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 2)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1708 (6.67 KB)\n",
            "Trainable params: 1708 (6.67 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_X, train_y, epochs = 100, batch_size = 100, verbose = 2, validation_data= (test_X,test_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4eba27d6-3030-4eba-adce-f519e4807ebd",
        "id": "uS8pg85brhdm"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "4/4 - 1s - loss: 0.7818 - accuracy: 0.3467 - val_loss: 0.7453 - val_accuracy: 0.4327 - 1s/epoch - 273ms/step\n",
            "Epoch 2/100\n",
            "4/4 - 0s - loss: 0.7793 - accuracy: 0.3467 - val_loss: 0.7437 - val_accuracy: 0.4327 - 59ms/epoch - 15ms/step\n",
            "Epoch 3/100\n",
            "4/4 - 0s - loss: 0.7768 - accuracy: 0.3467 - val_loss: 0.7421 - val_accuracy: 0.4327 - 41ms/epoch - 10ms/step\n",
            "Epoch 4/100\n",
            "4/4 - 0s - loss: 0.7744 - accuracy: 0.3467 - val_loss: 0.7405 - val_accuracy: 0.4327 - 57ms/epoch - 14ms/step\n",
            "Epoch 5/100\n",
            "4/4 - 0s - loss: 0.7720 - accuracy: 0.3467 - val_loss: 0.7390 - val_accuracy: 0.4327 - 62ms/epoch - 15ms/step\n",
            "Epoch 6/100\n",
            "4/4 - 0s - loss: 0.7696 - accuracy: 0.3467 - val_loss: 0.7375 - val_accuracy: 0.4327 - 41ms/epoch - 10ms/step\n",
            "Epoch 7/100\n",
            "4/4 - 0s - loss: 0.7674 - accuracy: 0.3467 - val_loss: 0.7360 - val_accuracy: 0.4327 - 57ms/epoch - 14ms/step\n",
            "Epoch 8/100\n",
            "4/4 - 0s - loss: 0.7651 - accuracy: 0.3467 - val_loss: 0.7345 - val_accuracy: 0.4327 - 81ms/epoch - 20ms/step\n",
            "Epoch 9/100\n",
            "4/4 - 0s - loss: 0.7629 - accuracy: 0.3467 - val_loss: 0.7331 - val_accuracy: 0.4327 - 82ms/epoch - 20ms/step\n",
            "Epoch 10/100\n",
            "4/4 - 0s - loss: 0.7607 - accuracy: 0.3467 - val_loss: 0.7318 - val_accuracy: 0.4327 - 75ms/epoch - 19ms/step\n",
            "Epoch 11/100\n",
            "4/4 - 0s - loss: 0.7586 - accuracy: 0.3467 - val_loss: 0.7304 - val_accuracy: 0.4327 - 77ms/epoch - 19ms/step\n",
            "Epoch 12/100\n",
            "4/4 - 0s - loss: 0.7565 - accuracy: 0.3467 - val_loss: 0.7291 - val_accuracy: 0.4327 - 88ms/epoch - 22ms/step\n",
            "Epoch 13/100\n",
            "4/4 - 0s - loss: 0.7545 - accuracy: 0.3467 - val_loss: 0.7279 - val_accuracy: 0.4327 - 79ms/epoch - 20ms/step\n",
            "Epoch 14/100\n",
            "4/4 - 0s - loss: 0.7525 - accuracy: 0.3467 - val_loss: 0.7266 - val_accuracy: 0.4327 - 71ms/epoch - 18ms/step\n",
            "Epoch 15/100\n",
            "4/4 - 0s - loss: 0.7505 - accuracy: 0.3467 - val_loss: 0.7254 - val_accuracy: 0.4327 - 74ms/epoch - 18ms/step\n",
            "Epoch 16/100\n",
            "4/4 - 0s - loss: 0.7486 - accuracy: 0.3467 - val_loss: 0.7243 - val_accuracy: 0.4327 - 65ms/epoch - 16ms/step\n",
            "Epoch 17/100\n",
            "4/4 - 0s - loss: 0.7467 - accuracy: 0.3467 - val_loss: 0.7231 - val_accuracy: 0.4327 - 74ms/epoch - 18ms/step\n",
            "Epoch 18/100\n",
            "4/4 - 0s - loss: 0.7449 - accuracy: 0.3467 - val_loss: 0.7220 - val_accuracy: 0.4327 - 88ms/epoch - 22ms/step\n",
            "Epoch 19/100\n",
            "4/4 - 0s - loss: 0.7430 - accuracy: 0.3467 - val_loss: 0.7209 - val_accuracy: 0.4327 - 72ms/epoch - 18ms/step\n",
            "Epoch 20/100\n",
            "4/4 - 0s - loss: 0.7412 - accuracy: 0.3467 - val_loss: 0.7198 - val_accuracy: 0.4327 - 72ms/epoch - 18ms/step\n",
            "Epoch 21/100\n",
            "4/4 - 0s - loss: 0.7395 - accuracy: 0.3467 - val_loss: 0.7188 - val_accuracy: 0.4327 - 82ms/epoch - 20ms/step\n",
            "Epoch 22/100\n",
            "4/4 - 0s - loss: 0.7378 - accuracy: 0.3467 - val_loss: 0.7178 - val_accuracy: 0.4327 - 82ms/epoch - 21ms/step\n",
            "Epoch 23/100\n",
            "4/4 - 0s - loss: 0.7361 - accuracy: 0.3467 - val_loss: 0.7168 - val_accuracy: 0.4327 - 63ms/epoch - 16ms/step\n",
            "Epoch 24/100\n",
            "4/4 - 0s - loss: 0.7344 - accuracy: 0.3467 - val_loss: 0.7158 - val_accuracy: 0.4327 - 74ms/epoch - 18ms/step\n",
            "Epoch 25/100\n",
            "4/4 - 0s - loss: 0.7328 - accuracy: 0.3467 - val_loss: 0.7149 - val_accuracy: 0.4327 - 71ms/epoch - 18ms/step\n",
            "Epoch 26/100\n",
            "4/4 - 0s - loss: 0.7312 - accuracy: 0.3467 - val_loss: 0.7139 - val_accuracy: 0.4327 - 62ms/epoch - 16ms/step\n",
            "Epoch 27/100\n",
            "4/4 - 0s - loss: 0.7297 - accuracy: 0.3467 - val_loss: 0.7131 - val_accuracy: 0.4327 - 78ms/epoch - 19ms/step\n",
            "Epoch 28/100\n",
            "4/4 - 0s - loss: 0.7281 - accuracy: 0.3467 - val_loss: 0.7122 - val_accuracy: 0.4327 - 75ms/epoch - 19ms/step\n",
            "Epoch 29/100\n",
            "4/4 - 0s - loss: 0.7266 - accuracy: 0.3467 - val_loss: 0.7113 - val_accuracy: 0.4327 - 72ms/epoch - 18ms/step\n",
            "Epoch 30/100\n",
            "4/4 - 0s - loss: 0.7252 - accuracy: 0.3467 - val_loss: 0.7105 - val_accuracy: 0.4327 - 74ms/epoch - 18ms/step\n",
            "Epoch 31/100\n",
            "4/4 - 0s - loss: 0.7237 - accuracy: 0.3467 - val_loss: 0.7097 - val_accuracy: 0.4327 - 78ms/epoch - 19ms/step\n",
            "Epoch 32/100\n",
            "4/4 - 0s - loss: 0.7224 - accuracy: 0.3467 - val_loss: 0.7089 - val_accuracy: 0.4327 - 72ms/epoch - 18ms/step\n",
            "Epoch 33/100\n",
            "4/4 - 0s - loss: 0.7209 - accuracy: 0.3467 - val_loss: 0.7082 - val_accuracy: 0.4327 - 82ms/epoch - 21ms/step\n",
            "Epoch 34/100\n",
            "4/4 - 0s - loss: 0.7195 - accuracy: 0.3467 - val_loss: 0.7074 - val_accuracy: 0.4327 - 79ms/epoch - 20ms/step\n",
            "Epoch 35/100\n",
            "4/4 - 0s - loss: 0.7182 - accuracy: 0.3467 - val_loss: 0.7067 - val_accuracy: 0.4327 - 80ms/epoch - 20ms/step\n",
            "Epoch 36/100\n",
            "4/4 - 0s - loss: 0.7169 - accuracy: 0.3467 - val_loss: 0.7060 - val_accuracy: 0.4327 - 88ms/epoch - 22ms/step\n",
            "Epoch 37/100\n",
            "4/4 - 0s - loss: 0.7156 - accuracy: 0.3467 - val_loss: 0.7053 - val_accuracy: 0.4327 - 90ms/epoch - 22ms/step\n",
            "Epoch 38/100\n",
            "4/4 - 0s - loss: 0.7143 - accuracy: 0.3467 - val_loss: 0.7046 - val_accuracy: 0.4327 - 75ms/epoch - 19ms/step\n",
            "Epoch 39/100\n",
            "4/4 - 0s - loss: 0.7131 - accuracy: 0.3467 - val_loss: 0.7040 - val_accuracy: 0.4327 - 79ms/epoch - 20ms/step\n",
            "Epoch 40/100\n",
            "4/4 - 0s - loss: 0.7119 - accuracy: 0.3467 - val_loss: 0.7033 - val_accuracy: 0.4327 - 78ms/epoch - 19ms/step\n",
            "Epoch 41/100\n",
            "4/4 - 0s - loss: 0.7107 - accuracy: 0.3467 - val_loss: 0.7027 - val_accuracy: 0.4327 - 76ms/epoch - 19ms/step\n",
            "Epoch 42/100\n",
            "4/4 - 0s - loss: 0.7095 - accuracy: 0.3467 - val_loss: 0.7021 - val_accuracy: 0.4327 - 81ms/epoch - 20ms/step\n",
            "Epoch 43/100\n",
            "4/4 - 0s - loss: 0.7084 - accuracy: 0.3467 - val_loss: 0.7015 - val_accuracy: 0.4327 - 78ms/epoch - 20ms/step\n",
            "Epoch 44/100\n",
            "4/4 - 0s - loss: 0.7072 - accuracy: 0.3467 - val_loss: 0.7010 - val_accuracy: 0.4327 - 71ms/epoch - 18ms/step\n",
            "Epoch 45/100\n",
            "4/4 - 0s - loss: 0.7061 - accuracy: 0.3467 - val_loss: 0.7004 - val_accuracy: 0.4327 - 78ms/epoch - 20ms/step\n",
            "Epoch 46/100\n",
            "4/4 - 0s - loss: 0.7050 - accuracy: 0.3467 - val_loss: 0.6999 - val_accuracy: 0.4327 - 80ms/epoch - 20ms/step\n",
            "Epoch 47/100\n",
            "4/4 - 0s - loss: 0.7040 - accuracy: 0.3467 - val_loss: 0.6994 - val_accuracy: 0.4327 - 66ms/epoch - 16ms/step\n",
            "Epoch 48/100\n",
            "4/4 - 0s - loss: 0.7029 - accuracy: 0.3467 - val_loss: 0.6988 - val_accuracy: 0.4327 - 74ms/epoch - 18ms/step\n",
            "Epoch 49/100\n",
            "4/4 - 0s - loss: 0.7019 - accuracy: 0.3467 - val_loss: 0.6984 - val_accuracy: 0.4327 - 80ms/epoch - 20ms/step\n",
            "Epoch 50/100\n",
            "4/4 - 0s - loss: 0.7009 - accuracy: 0.3467 - val_loss: 0.6979 - val_accuracy: 0.4327 - 67ms/epoch - 17ms/step\n",
            "Epoch 51/100\n",
            "4/4 - 0s - loss: 0.6999 - accuracy: 0.3467 - val_loss: 0.6974 - val_accuracy: 0.4327 - 87ms/epoch - 22ms/step\n",
            "Epoch 52/100\n",
            "4/4 - 0s - loss: 0.6989 - accuracy: 0.3467 - val_loss: 0.6970 - val_accuracy: 0.4327 - 83ms/epoch - 21ms/step\n",
            "Epoch 53/100\n",
            "4/4 - 0s - loss: 0.6980 - accuracy: 0.3467 - val_loss: 0.6965 - val_accuracy: 0.4327 - 86ms/epoch - 21ms/step\n",
            "Epoch 54/100\n",
            "4/4 - 0s - loss: 0.6970 - accuracy: 0.3467 - val_loss: 0.6961 - val_accuracy: 0.4327 - 82ms/epoch - 20ms/step\n",
            "Epoch 55/100\n",
            "4/4 - 0s - loss: 0.6961 - accuracy: 0.3995 - val_loss: 0.6957 - val_accuracy: 0.5731 - 66ms/epoch - 16ms/step\n",
            "Epoch 56/100\n",
            "4/4 - 0s - loss: 0.6952 - accuracy: 0.6533 - val_loss: 0.6953 - val_accuracy: 0.5673 - 48ms/epoch - 12ms/step\n",
            "Epoch 57/100\n",
            "4/4 - 0s - loss: 0.6943 - accuracy: 0.6533 - val_loss: 0.6949 - val_accuracy: 0.5673 - 42ms/epoch - 10ms/step\n",
            "Epoch 58/100\n",
            "4/4 - 0s - loss: 0.6935 - accuracy: 0.6533 - val_loss: 0.6945 - val_accuracy: 0.5673 - 60ms/epoch - 15ms/step\n",
            "Epoch 59/100\n",
            "4/4 - 0s - loss: 0.6926 - accuracy: 0.6533 - val_loss: 0.6941 - val_accuracy: 0.5673 - 47ms/epoch - 12ms/step\n",
            "Epoch 60/100\n",
            "4/4 - 0s - loss: 0.6918 - accuracy: 0.6533 - val_loss: 0.6938 - val_accuracy: 0.5673 - 44ms/epoch - 11ms/step\n",
            "Epoch 61/100\n",
            "4/4 - 0s - loss: 0.6910 - accuracy: 0.6533 - val_loss: 0.6934 - val_accuracy: 0.5673 - 59ms/epoch - 15ms/step\n",
            "Epoch 62/100\n",
            "4/4 - 0s - loss: 0.6902 - accuracy: 0.6533 - val_loss: 0.6931 - val_accuracy: 0.5673 - 60ms/epoch - 15ms/step\n",
            "Epoch 63/100\n",
            "4/4 - 0s - loss: 0.6894 - accuracy: 0.6533 - val_loss: 0.6927 - val_accuracy: 0.5673 - 45ms/epoch - 11ms/step\n",
            "Epoch 64/100\n",
            "4/4 - 0s - loss: 0.6886 - accuracy: 0.6533 - val_loss: 0.6924 - val_accuracy: 0.5673 - 48ms/epoch - 12ms/step\n",
            "Epoch 65/100\n",
            "4/4 - 0s - loss: 0.6878 - accuracy: 0.6533 - val_loss: 0.6921 - val_accuracy: 0.5673 - 62ms/epoch - 15ms/step\n",
            "Epoch 66/100\n",
            "4/4 - 0s - loss: 0.6871 - accuracy: 0.6533 - val_loss: 0.6918 - val_accuracy: 0.5673 - 60ms/epoch - 15ms/step\n",
            "Epoch 67/100\n",
            "4/4 - 0s - loss: 0.6864 - accuracy: 0.6533 - val_loss: 0.6915 - val_accuracy: 0.5673 - 47ms/epoch - 12ms/step\n",
            "Epoch 68/100\n",
            "4/4 - 0s - loss: 0.6856 - accuracy: 0.6533 - val_loss: 0.6913 - val_accuracy: 0.5673 - 64ms/epoch - 16ms/step\n",
            "Epoch 69/100\n",
            "4/4 - 0s - loss: 0.6849 - accuracy: 0.6533 - val_loss: 0.6910 - val_accuracy: 0.5673 - 63ms/epoch - 16ms/step\n",
            "Epoch 70/100\n",
            "4/4 - 0s - loss: 0.6842 - accuracy: 0.6533 - val_loss: 0.6907 - val_accuracy: 0.5673 - 48ms/epoch - 12ms/step\n",
            "Epoch 71/100\n",
            "4/4 - 0s - loss: 0.6835 - accuracy: 0.6533 - val_loss: 0.6905 - val_accuracy: 0.5673 - 46ms/epoch - 12ms/step\n",
            "Epoch 72/100\n",
            "4/4 - 0s - loss: 0.6829 - accuracy: 0.6533 - val_loss: 0.6902 - val_accuracy: 0.5673 - 61ms/epoch - 15ms/step\n",
            "Epoch 73/100\n",
            "4/4 - 0s - loss: 0.6822 - accuracy: 0.6533 - val_loss: 0.6900 - val_accuracy: 0.5673 - 46ms/epoch - 12ms/step\n",
            "Epoch 74/100\n",
            "4/4 - 0s - loss: 0.6816 - accuracy: 0.6533 - val_loss: 0.6898 - val_accuracy: 0.5673 - 48ms/epoch - 12ms/step\n",
            "Epoch 75/100\n",
            "4/4 - 0s - loss: 0.6809 - accuracy: 0.6533 - val_loss: 0.6895 - val_accuracy: 0.5673 - 62ms/epoch - 15ms/step\n",
            "Epoch 76/100\n",
            "4/4 - 0s - loss: 0.6803 - accuracy: 0.6533 - val_loss: 0.6893 - val_accuracy: 0.5673 - 62ms/epoch - 15ms/step\n",
            "Epoch 77/100\n",
            "4/4 - 0s - loss: 0.6797 - accuracy: 0.6533 - val_loss: 0.6891 - val_accuracy: 0.5673 - 49ms/epoch - 12ms/step\n",
            "Epoch 78/100\n",
            "4/4 - 0s - loss: 0.6791 - accuracy: 0.6533 - val_loss: 0.6889 - val_accuracy: 0.5673 - 61ms/epoch - 15ms/step\n",
            "Epoch 79/100\n",
            "4/4 - 0s - loss: 0.6785 - accuracy: 0.6533 - val_loss: 0.6887 - val_accuracy: 0.5673 - 48ms/epoch - 12ms/step\n",
            "Epoch 80/100\n",
            "4/4 - 0s - loss: 0.6780 - accuracy: 0.6533 - val_loss: 0.6886 - val_accuracy: 0.5673 - 61ms/epoch - 15ms/step\n",
            "Epoch 81/100\n",
            "4/4 - 0s - loss: 0.6774 - accuracy: 0.6533 - val_loss: 0.6884 - val_accuracy: 0.5673 - 61ms/epoch - 15ms/step\n",
            "Epoch 82/100\n",
            "4/4 - 0s - loss: 0.6768 - accuracy: 0.6533 - val_loss: 0.6882 - val_accuracy: 0.5673 - 50ms/epoch - 12ms/step\n",
            "Epoch 83/100\n",
            "4/4 - 0s - loss: 0.6763 - accuracy: 0.6533 - val_loss: 0.6880 - val_accuracy: 0.5673 - 50ms/epoch - 13ms/step\n",
            "Epoch 84/100\n",
            "4/4 - 0s - loss: 0.6758 - accuracy: 0.6533 - val_loss: 0.6879 - val_accuracy: 0.5673 - 48ms/epoch - 12ms/step\n",
            "Epoch 85/100\n",
            "4/4 - 0s - loss: 0.6752 - accuracy: 0.6533 - val_loss: 0.6877 - val_accuracy: 0.5673 - 61ms/epoch - 15ms/step\n",
            "Epoch 86/100\n",
            "4/4 - 0s - loss: 0.6747 - accuracy: 0.6533 - val_loss: 0.6876 - val_accuracy: 0.5673 - 46ms/epoch - 12ms/step\n",
            "Epoch 87/100\n",
            "4/4 - 0s - loss: 0.6742 - accuracy: 0.6533 - val_loss: 0.6874 - val_accuracy: 0.5673 - 62ms/epoch - 15ms/step\n",
            "Epoch 88/100\n",
            "4/4 - 0s - loss: 0.6737 - accuracy: 0.6533 - val_loss: 0.6873 - val_accuracy: 0.5673 - 48ms/epoch - 12ms/step\n",
            "Epoch 89/100\n",
            "4/4 - 0s - loss: 0.6732 - accuracy: 0.6533 - val_loss: 0.6872 - val_accuracy: 0.5673 - 59ms/epoch - 15ms/step\n",
            "Epoch 90/100\n",
            "4/4 - 0s - loss: 0.6727 - accuracy: 0.6533 - val_loss: 0.6870 - val_accuracy: 0.5673 - 45ms/epoch - 11ms/step\n",
            "Epoch 91/100\n",
            "4/4 - 0s - loss: 0.6723 - accuracy: 0.6533 - val_loss: 0.6869 - val_accuracy: 0.5673 - 46ms/epoch - 12ms/step\n",
            "Epoch 92/100\n",
            "4/4 - 0s - loss: 0.6718 - accuracy: 0.6533 - val_loss: 0.6868 - val_accuracy: 0.5673 - 53ms/epoch - 13ms/step\n",
            "Epoch 93/100\n",
            "4/4 - 0s - loss: 0.6713 - accuracy: 0.6533 - val_loss: 0.6867 - val_accuracy: 0.5673 - 46ms/epoch - 12ms/step\n",
            "Epoch 94/100\n",
            "4/4 - 0s - loss: 0.6709 - accuracy: 0.6533 - val_loss: 0.6866 - val_accuracy: 0.5673 - 61ms/epoch - 15ms/step\n",
            "Epoch 95/100\n",
            "4/4 - 0s - loss: 0.6705 - accuracy: 0.6533 - val_loss: 0.6865 - val_accuracy: 0.5673 - 47ms/epoch - 12ms/step\n",
            "Epoch 96/100\n",
            "4/4 - 0s - loss: 0.6700 - accuracy: 0.6533 - val_loss: 0.6864 - val_accuracy: 0.5673 - 47ms/epoch - 12ms/step\n",
            "Epoch 97/100\n",
            "4/4 - 0s - loss: 0.6696 - accuracy: 0.6533 - val_loss: 0.6863 - val_accuracy: 0.5673 - 58ms/epoch - 15ms/step\n",
            "Epoch 98/100\n",
            "4/4 - 0s - loss: 0.6692 - accuracy: 0.6533 - val_loss: 0.6862 - val_accuracy: 0.5673 - 46ms/epoch - 12ms/step\n",
            "Epoch 99/100\n",
            "4/4 - 0s - loss: 0.6688 - accuracy: 0.6533 - val_loss: 0.6861 - val_accuracy: 0.5673 - 54ms/epoch - 13ms/step\n",
            "Epoch 100/100\n",
            "4/4 - 0s - loss: 0.6684 - accuracy: 0.6533 - val_loss: 0.6861 - val_accuracy: 0.5673 - 62ms/epoch - 15ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7866e1423be0>"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(train_X,train_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b37cbf3-bbba-4f68-edae-c3e33400336d",
        "id": "LyJJL4Hzrhdm"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6681 - accuracy: 0.6533\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6681183576583862, 0.6532663106918335]"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_X,test_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a36ae48-cc77-41a1-f80a-0ed1eec45136",
        "id": "0ozWjXwQrhdm"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 4ms/step - loss: 0.6861 - accuracy: 0.5673\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6860703825950623, 0.567251443862915]"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(test_X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f522427-4989-430c-a8b1-53b52084df03",
        "id": "ruoxTsB0rhdm"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.39719516, 0.60280484],\n",
              "       [0.39720383, 0.6027962 ],\n",
              "       [0.39700028, 0.60299975],\n",
              "       [0.39736298, 0.60263705],\n",
              "       [0.39761442, 0.6023856 ],\n",
              "       [0.39734462, 0.6026554 ],\n",
              "       [0.39701682, 0.6029832 ],\n",
              "       [0.39761442, 0.6023856 ],\n",
              "       [0.3969872 , 0.60301286],\n",
              "       [0.39698976, 0.60301024],\n",
              "       [0.3969864 , 0.60301363],\n",
              "       [0.39699176, 0.6030082 ],\n",
              "       [0.39732558, 0.6026744 ],\n",
              "       [0.39699712, 0.60300285],\n",
              "       [0.39761442, 0.6023856 ],\n",
              "       [0.39758906, 0.602411  ],\n",
              "       [0.39761442, 0.6023856 ],\n",
              "       [0.39719516, 0.60280484],\n",
              "       [0.3971597 , 0.60284024],\n",
              "       [0.39761442, 0.6023856 ],\n",
              "       [0.39736336, 0.60263664],\n",
              "       [0.39701894, 0.6029811 ],\n",
              "       [0.3976137 , 0.6023863 ],\n",
              "       [0.3972697 , 0.6027303 ],\n",
              "       [0.39719516, 0.60280484],\n",
              "       [0.39735427, 0.60264575],\n",
              "       [0.39700454, 0.60299546],\n",
              "       [0.39719516, 0.60280484],\n",
              "       [0.39719537, 0.60280466],\n",
              "       [0.39719516, 0.60280484],\n",
              "       [0.3971836 , 0.6028164 ],\n",
              "       [0.3973345 , 0.6026655 ],\n",
              "       [0.39702585, 0.6029742 ],\n",
              "       [0.39719516, 0.60280484],\n",
              "       [0.39703995, 0.60296005],\n",
              "       [0.39733934, 0.6026606 ],\n",
              "       [0.397027  , 0.602973  ],\n",
              "       [0.39735648, 0.60264355],\n",
              "       [0.3970075 , 0.60299253],\n",
              "       [0.39698938, 0.60301065],\n",
              "       [0.39719954, 0.6028005 ],\n",
              "       [0.39699206, 0.603008  ],\n",
              "       [0.39725074, 0.6027493 ],\n",
              "       [0.39725012, 0.6027499 ],\n",
              "       [0.39698642, 0.6030135 ],\n",
              "       [0.39719516, 0.60280484],\n",
              "       [0.39711457, 0.6028854 ],\n",
              "       [0.39719516, 0.60280484],\n",
              "       [0.39701608, 0.6029839 ],\n",
              "       [0.39712182, 0.60287815],\n",
              "       [0.39719516, 0.60280484],\n",
              "       [0.39719516, 0.60280484],\n",
              "       [0.39734063, 0.60265934],\n",
              "       [0.39698565, 0.6030144 ],\n",
              "       [0.39719465, 0.6028054 ],\n",
              "       [0.3972364 , 0.6027636 ],\n",
              "       [0.39719516, 0.60280484],\n",
              "       [0.3975881 , 0.60241187],\n",
              "       [0.39698607, 0.60301393],\n",
              "       [0.39759892, 0.602401  ],\n",
              "       [0.39761442, 0.6023856 ],\n",
              "       [0.39698616, 0.6030138 ],\n",
              "       [0.39700222, 0.6029977 ],\n",
              "       [0.397608  , 0.60239196],\n",
              "       [0.39699683, 0.6030032 ],\n",
              "       [0.39719513, 0.60280484],\n",
              "       [0.39702484, 0.60297513],\n",
              "       [0.39698535, 0.60301465],\n",
              "       [0.39719668, 0.60280335],\n",
              "       [0.39785656, 0.6021434 ],\n",
              "       [0.3969955 , 0.6030045 ],\n",
              "       [0.39761442, 0.6023856 ],\n",
              "       [0.3969852 , 0.60301477],\n",
              "       [0.39699233, 0.6030077 ],\n",
              "       [0.39719495, 0.602805  ],\n",
              "       [0.39736176, 0.6026382 ],\n",
              "       [0.39735115, 0.60264885],\n",
              "       [0.39761442, 0.6023856 ],\n",
              "       [0.39698583, 0.60301423],\n",
              "       [0.39761198, 0.602388  ],\n",
              "       [0.39735708, 0.6026429 ],\n",
              "       [0.3971935 , 0.6028065 ],\n",
              "       [0.39719516, 0.60280484],\n",
              "       [0.39719516, 0.60280484],\n",
              "       [0.3970119 , 0.6029881 ],\n",
              "       [0.39723715, 0.6027628 ],\n",
              "       [0.3973537 , 0.60264635],\n",
              "       [0.39720926, 0.6027907 ],\n",
              "       [0.3969864 , 0.60301363],\n",
              "       [0.39761442, 0.6023856 ],\n",
              "       [0.3973614 , 0.6026386 ],\n",
              "       [0.39719516, 0.60280484],\n",
              "       [0.39716628, 0.6028337 ],\n",
              "       [0.39700842, 0.6029916 ],\n",
              "       [0.39719513, 0.6028049 ],\n",
              "       [0.3972458 , 0.60275424],\n",
              "       [0.39761442, 0.6023856 ],\n",
              "       [0.39746192, 0.60253805],\n",
              "       [0.39761442, 0.6023856 ],\n",
              "       [0.39719516, 0.60280484],\n",
              "       [0.39721495, 0.60278505],\n",
              "       [0.3970023 , 0.6029977 ],\n",
              "       [0.39704043, 0.60295963],\n",
              "       [0.3971355 , 0.60286456],\n",
              "       [0.39719507, 0.6028049 ],\n",
              "       [0.39744297, 0.602557  ],\n",
              "       [0.39716375, 0.6028362 ],\n",
              "       [0.39715752, 0.60284245],\n",
              "       [0.39699855, 0.6030015 ],\n",
              "       [0.39699614, 0.6030038 ],\n",
              "       [0.39719516, 0.60280484],\n",
              "       [0.39761442, 0.6023856 ],\n",
              "       [0.39761442, 0.6023856 ],\n",
              "       [0.39699033, 0.6030097 ],\n",
              "       [0.3969864 , 0.60301363],\n",
              "       [0.3969927 , 0.60300726],\n",
              "       [0.39698586, 0.6030141 ],\n",
              "       [0.39719516, 0.60280484],\n",
              "       [0.39701653, 0.6029834 ],\n",
              "       [0.39712706, 0.60287297],\n",
              "       [0.39699528, 0.60300475],\n",
              "       [0.39698678, 0.60301316],\n",
              "       [0.39700177, 0.60299826],\n",
              "       [0.3969861 , 0.60301393],\n",
              "       [0.39698574, 0.60301423],\n",
              "       [0.39734805, 0.60265195],\n",
              "       [0.39727473, 0.6027253 ],\n",
              "       [0.3970354 , 0.60296464],\n",
              "       [0.3970135 , 0.6029865 ],\n",
              "       [0.39704043, 0.6029596 ],\n",
              "       [0.39719498, 0.602805  ],\n",
              "       [0.39698756, 0.6030125 ],\n",
              "       [0.39703363, 0.60296637],\n",
              "       [0.39703238, 0.60296756],\n",
              "       [0.3970091 , 0.6029909 ],\n",
              "       [0.3976137 , 0.6023863 ],\n",
              "       [0.39719516, 0.60280484],\n",
              "       [0.3973552 , 0.6026448 ],\n",
              "       [0.39698526, 0.60301477],\n",
              "       [0.39711776, 0.6028822 ],\n",
              "       [0.39698708, 0.6030129 ],\n",
              "       [0.39719516, 0.60280484],\n",
              "       [0.39719516, 0.60280484],\n",
              "       [0.39735562, 0.6026443 ],\n",
              "       [0.39720568, 0.60279435],\n",
              "       [0.39735717, 0.6026429 ],\n",
              "       [0.39700016, 0.6029998 ],\n",
              "       [0.39761442, 0.6023856 ],\n",
              "       [0.39698556, 0.6030144 ],\n",
              "       [0.3973582 , 0.60264176],\n",
              "       [0.39743775, 0.60256225],\n",
              "       [0.39735782, 0.6026422 ],\n",
              "       [0.3969854 , 0.6030146 ],\n",
              "       [0.39732003, 0.6026799 ],\n",
              "       [0.39740992, 0.6025901 ],\n",
              "       [0.39698592, 0.6030141 ],\n",
              "       [0.3970302 , 0.60296977],\n",
              "       [0.3974044 , 0.6025956 ],\n",
              "       [0.39719516, 0.60280484],\n",
              "       [0.39698547, 0.6030146 ],\n",
              "       [0.3973558 , 0.60264415],\n",
              "       [0.397425  , 0.602575  ],\n",
              "       [0.39732036, 0.60267967],\n",
              "       [0.3971952 , 0.60280484],\n",
              "       [0.39725178, 0.60274816],\n",
              "       [0.39698586, 0.6030141 ],\n",
              "       [0.3970004 , 0.6029996 ],\n",
              "       [0.39718762, 0.60281235],\n",
              "       [0.39703262, 0.6029674 ],\n",
              "       [0.3972996 , 0.60270035],\n",
              "       [0.39698556, 0.6030144 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(model.predict(test_X), axis = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJOu5VKwrhdn",
        "outputId": "55189e57-84bf-49e4-9c81-9db62ee3bf58"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(np.array([6,2,4]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1C6bifz6rhdn",
        "outputId": "4c38ca3f-9511-4b6f-f428-6dee3aa40eb1"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NFDjzQ2VsP47"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}